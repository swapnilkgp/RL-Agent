{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gridworld\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "world=gridworld.GridWorld()\n",
    "minus_inf=-99\n",
    "value_tables=np.full((world.WORLD_HEIGHT,world.WORLD_WIDTH),minus_inf,dtype=float)\n",
    "optimal_action=np.full((world.WORLD_HEIGHT,world.WORLD_WIDTH),-1)\n",
    "value_tables[world.GOAL[0]][world.GOAL[1]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_value(current_state):\n",
    "    action_values=np.array([0,0,0,0])\n",
    "    for action in world.ACTIONS:\n",
    "        new_state,reward=world.step(current_state,action)\n",
    "        if(world.WIND[new_state[0]]==0):\n",
    "            action_values[action]=reward+value_tables[new_state[0]][new_state[1]]\n",
    "        else:\n",
    "            if(action==0 or action==1):\n",
    "                if(new_state[1]==current_state[1]):\n",
    "                    state2=value_tables[new_state[0]][new_state[1]]\n",
    "                    state8=value_tables[new_state[0]][max(0,new_state[1]-world.WIND[new_state[0]])]\n",
    "                else:\n",
    "                    state8=value_tables[new_state[0]][new_state[1]]\n",
    "                    state2=value_tables[new_state[0]][current_state[1]]\n",
    "            elif(action==3):\n",
    "                if(current_state[1]==world.WORLD_WIDTH-1):\n",
    "                    state2=value_tables[current_state[0]][current_state[1]]\n",
    "                    state8=value_tables[current_state[0]][max(0,current_state[1]-world.WIND[current_state[0]])]\n",
    "                else:\n",
    "                    state2=value_tables[current_state[0]][current_state[1]+1]\n",
    "                    state8=value_tables[current_state[0]][max(0,1+current_state[1]-world.WIND[current_state[0]])]\n",
    "            elif(action==2):\n",
    "                if(current_state[1]==0):\n",
    "                    state2=value_tables[current_state[0]][current_state[1]]\n",
    "                    state8=value_tables[current_state[0]][max(0,current_state[1]-world.WIND[current_state[0]])]\n",
    "                else:\n",
    "                    state2=value_tables[current_state[0]][current_state[1]-1]\n",
    "                    state8=value_tables[current_state[0]][max(0,-1+current_state[1]-world.WIND[current_state[0]])]\n",
    "            action_values[action]=reward+(1-world.WIND_PROB)*state2+(world.WIND_PROB)*state8\n",
    "    max_val, max_action=action_values[0],0\n",
    "    for i in range (4):\n",
    "        if(action_values[i]>max_val): max_val,max_action=action_values[i],i\n",
    "    return max_val,max_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(10000):\n",
    "    for i in range (world.WORLD_HEIGHT):\n",
    "        for j in range (world.WORLD_WIDTH):\n",
    "            if [i,j] not in (world.obstacles+[world.GOAL]):\n",
    "                if(value_tables[i][j]<(assign_value([i,j])[0])):\n",
    "                    value_tables[i][j],optimal_action[i][j]=assign_value([i,j])[0],assign_value([i,j])[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 3  3  3  3  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 0  0  0 -1  1  1  1  1  1  1  1  1  1  1  1]\n",
      " [ 0  0  0 -1  3  3  3  3  3  3  3  3  3  1  1]\n",
      " [ 0  0  0  3  0  0  0  0  0  0  0  0  1  1  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  1  1  1  1  1]\n",
      " [ 0  0  0  0  0  0  0  3  3  1  1  1  1  2  2]\n",
      " [ 0  0  0 -1  3  3  3  0 -1  1  1  1  2  2  2]\n",
      " [ 0  0  0 -1  0  0  0  0 -1  3  3 -1  2  2  2]\n",
      " [ 0  0  0 -1  0  0  0  0 -1  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(optimal_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-20. -19. -18. -17. -16. -15. -14. -13. -12. -11. -10.  -9.  -8.  -7.\n",
      "   -7.]\n",
      " [-19. -18. -17. -16. -15. -14. -13. -12. -11. -10.  -9.  -8.  -7.  -6.\n",
      "   -6.]\n",
      " [-20. -19. -18. -99. -14. -13. -12. -11. -10.  -9.  -8.  -7.  -6.  -5.\n",
      "   -5.]\n",
      " [-21. -20. -19. -99. -13. -12. -11. -10.  -9.  -8.  -7.  -6.  -5.  -4.\n",
      "   -4.]\n",
      " [-22. -21. -20. -19. -14. -13. -12. -11. -10.  -9.  -8.  -7.  -3.  -3.\n",
      "   -3.]\n",
      " [-23. -22. -21. -20. -19. -14. -13. -12. -11.  -8.  -3.  -2.  -2.  -3.\n",
      "   -3.]\n",
      " [-24. -23. -23. -22. -21. -19. -18. -13.  -8.  -3.  -2.  -1.  -2.  -2.\n",
      "   -3.]\n",
      " [-25. -24. -24. -99. -21. -20. -19. -18. -99.  -2.  -1.   0.  -1.  -2.\n",
      "   -3.]\n",
      " [-26. -25. -25. -99. -22. -21. -20. -19. -99.  -1.   0.   0.   0.  -1.\n",
      "   -2.]\n",
      " [-27. -26. -26. -99. -23. -22. -21. -20. -99.  -2.  -1.   0.  -1.  -2.\n",
      "   -3.]]\n"
     ]
    }
   ],
   "source": [
    "print(value_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Co-ordinate :  [6, 1]\n",
      "Co-ordinate at step  1  :  [5, 0]\n",
      "Co-ordinate at step  2  :  [4, 0]\n",
      "Co-ordinate at step  3  :  [3, 0]\n",
      "Co-ordinate at step  4  :  [2, 0]\n",
      "Co-ordinate at step  5  :  [1, 0]\n",
      "Co-ordinate at step  6  :  [1, 1]\n",
      "Co-ordinate at step  7  :  [1, 2]\n",
      "Co-ordinate at step  8  :  [1, 3]\n",
      "Co-ordinate at step  9  :  [1, 4]\n",
      "Co-ordinate at step  10  :  [2, 4]\n",
      "Co-ordinate at step  11  :  [3, 4]\n",
      "Co-ordinate at step  12  :  [3, 5]\n",
      "Co-ordinate at step  13  :  [3, 6]\n",
      "Co-ordinate at step  14  :  [3, 7]\n",
      "Co-ordinate at step  15  :  [3, 8]\n",
      "Co-ordinate at step  16  :  [3, 9]\n",
      "Co-ordinate at step  17  :  [3, 10]\n",
      "Co-ordinate at step  18  :  [3, 11]\n",
      "Co-ordinate at step  19  :  [3, 12]\n",
      "Co-ordinate at step  20  :  [3, 13]\n",
      "Co-ordinate at step  21  :  [4, 12]\n",
      "Co-ordinate at step  22  :  [5, 10]\n",
      "Co-ordinate at step  23  :  [6, 9]\n",
      "Co-ordinate at step  24  :  [7, 9]\n",
      "Co-ordinate at step  25  :  [8, 9]\n",
      "Co-ordinate at step  26  :  [8, 10]\n",
      "Co-ordinate at step  27  :  [8, 11]\n",
      "GOAL REACHED in most optimal way.\n",
      "Maximum possible reward :  -26.0\n"
     ]
    }
   ],
   "source": [
    "current_state=world.START\n",
    "total_reward=0\n",
    "cnt=1\n",
    "print(\"Initial Co-ordinate : \",current_state)\n",
    "while(current_state!=world.GOAL):\n",
    "    new_state,reward=world.step(current_state,optimal_action[current_state[0]][current_state[1]])\n",
    "    print(\"Co-ordinate at step \",cnt,\" : \",new_state)\n",
    "    total_reward+=reward\n",
    "    cnt+=1\n",
    "    current_state=new_state\n",
    "print(\"GOAL REACHED in most optimal way.\")\n",
    "print(\"Maximum possible reward : \",total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img=cv.imread(\"grid.png\")\n",
    "img=cv.resize(img,(1600,1100))\n",
    "current_state=world.START\n",
    "y=(current_state[0]+1)*50+(current_state[0]+2)*50\n",
    "x=(current_state[1]+1)*50+(current_state[1]+2)*50\n",
    "cv.circle(img,(x,y),40,(0,0,255),-1)\n",
    "while(current_state!=world.GOAL):\n",
    "    new_state,reward=world.step(current_state,optimal_action[current_state[0]][current_state[1]])\n",
    "    y=(new_state[0]+1)*50+(new_state[0]+2)*50\n",
    "    x=(new_state[1]+1)*50+(new_state[1]+2)*50\n",
    "    cv.circle(img,(x,y),40,(0,0,255),-1)\n",
    "    current_state=new_state\n",
    "cv.imwrite(\"path.jpeg\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "037f87f168f2dfc249800d7ce4fa7d08c5d2b244bc30b4230cc16b3b7e91dbd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
